{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 666\n",
    "DATA_FILE = '../Datasets/cats/data/breeds_data_final.pkl'\n",
    "IMAGES_DIR = '../Datasets/cats/images'\n",
    "FIGURES_DIR = '../Figures/'\n",
    "CHECKPOINTS_DIR = '../History'\n",
    "RESOLUTION = 128 # 128\n",
    "LABELS = 'coat' # 'breeds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>size</th>\n",
       "      <th>coat</th>\n",
       "      <th>breed</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Abyssinian/46620170_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Abyssinian/46463847_8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Abyssinian/46305208_12.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Abyssinian/46301725_13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Abyssinian/46293180_14.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67140</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Tuxedo/43781057_7295.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Tuxedo/43773439_7304.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67142</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Tuxedo/43773383_7305.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Tuxedo/43773168_7306.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67144</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>York Chocolate/46336858_40884.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41939 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender  size  coat  breed                              image\n",
       "3      1.0     0.0   3.0   2.0    0.0          Abyssinian/46620170_3.jpg\n",
       "7      0.0     1.0   2.0   2.0    0.0          Abyssinian/46463847_8.jpg\n",
       "11     2.0     1.0   2.0   2.0    0.0         Abyssinian/46305208_12.jpg\n",
       "12     0.0     0.0   2.0   2.0    0.0         Abyssinian/46301725_13.jpg\n",
       "13     3.0     1.0   3.0   2.0    0.0         Abyssinian/46293180_14.jpg\n",
       "...    ...     ...   ...   ...    ...                                ...\n",
       "67140  1.0     1.0   2.0   2.0   65.0           Tuxedo/43781057_7295.jpg\n",
       "67141  0.0     0.0   2.0   2.0   65.0           Tuxedo/43773439_7304.jpg\n",
       "67142  3.0     0.0   1.0   2.0   65.0           Tuxedo/43773383_7305.jpg\n",
       "67143  0.0     1.0   2.0   1.0   65.0           Tuxedo/43773168_7306.jpg\n",
       "67144  1.0     1.0   3.0   1.0   66.0  York Chocolate/46336858_40884.jpg\n",
       "\n",
       "[41939 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(DATA_FILE)\n",
    "# (Solved) PROBLEM: 26 unique breeds, but 66 included in final number of breeds, \n",
    "# lots of inaccuracy to account for here\n",
    "#len(data['breed'].unique())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cats data string convertor\n",
    "# Data was collected from Analysis/cats/cats_prediction_2.ipynb\n",
    "age_list = ['Adult', 'Baby', 'Senior', 'Young']\n",
    "gender_list = ['Female', 'Male']\n",
    "size_list = ['Extra Large', 'Large', 'Medium', 'Small']\n",
    "coat_list = ['Long', 'Medium', 'Short']\n",
    "breed_list = ['Abyssinian', 'American Bobtail', 'American Curl',\n",
    "        'American Shorthair', 'American Wirehair', 'Applehead Siamese',\n",
    "        'Balinese', 'Bengal', 'Birman', 'Bombay', 'British Shorthair',\n",
    "        'Burmese', 'Burmilla', 'Calico', 'Canadian Hairless', 'Chartreux',\n",
    "        'Chausie', 'Chinchilla', 'Cornish Rex', 'Cymric', 'Devon Rex',\n",
    "        'Dilute Calico', 'Dilute Tortoiseshell', 'Domestic Long Hair',\n",
    "        'Domestic Medium Hair', 'Domestic Short Hair', 'Egyptian Mau',\n",
    "        'Exotic Shorthair', 'Extra-Toes Cat - Hemingway Polydactyl',\n",
    "        'Havana', 'Himalayan', 'Japanese Bobtail', 'Javanese', 'Korat',\n",
    "        'LaPerm', 'Maine Coon', 'Manx', 'Munchkin', 'Nebelung',\n",
    "        'Norwegian Forest Cat', 'Ocicat', 'Oriental Long Hair',\n",
    "        'Oriental Short Hair', 'Oriental Tabby', 'Persian', 'Pixiebob',\n",
    "        'Ragamuffin', 'Ragdoll', 'Russian Blue', 'Scottish Fold',\n",
    "        'Selkirk Rex', 'Siamese', 'Siberian', 'Silver', 'Singapura',\n",
    "        'Snowshoe', 'Somali', 'Sphynx - Hairless Cat', 'Tabby', 'Tiger',\n",
    "        'Tonkinese', 'Torbie', 'Tortoiseshell', 'Turkish Angora',\n",
    "        'Turkish Van', 'Tuxedo', 'York Chocolate']\n",
    "\n",
    "#breed_list = np.empty(len(full_breed_list),dtype=object)\n",
    "#for i in range(len(full_breed_list)):\n",
    "#    if (i+1 in data['breed'].unique()):\n",
    "#        breed_list[i] = full_breed_list[i]\n",
    "\n",
    "#breed_list = breed_list[breed_list != None]\n",
    "#print(breed_list)\n",
    "\n",
    "def get_cat_string(cat, value):\n",
    "    if(cat == 'age'):\n",
    "        return age_list[int(value)]\n",
    "    elif(cat == 'gender'):\n",
    "        return gender_list[int(value)]\n",
    "    elif(cat == 'size'):\n",
    "        return size_list[int(value)]\n",
    "    elif(cat == 'coat'):\n",
    "        return coat_list[int(value)]\n",
    "    elif(cat == 'breed'):\n",
    "        return breed_list[int(value)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "- Label : coat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # Fix issues with truncated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from paths stored in the dataframe\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    for path in df['image']:\n",
    "        #print(os.path.join(IMAGES_DIR, path))\n",
    "        img = load_img(os.path.join(IMAGES_DIR, path), target_size=(RESOLUTION, RESOLUTION))\n",
    "        img = img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        #img = cv2.imread(os.path.join(IMAGES_DIR, path), cv2.COLOR_RGB2BGR)\n",
    "        #img = cv2.resize(img, (RESOLUTION, RESOLUTION))\n",
    "        images.append(img.astype(np.float32) / 255.0)\n",
    "        #images.append(img)\n",
    "    return np.vstack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = load_images(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data in analysis.ipynb\n",
    "print(data.iloc[:, 4].shape)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm doubting if ML can determine a cat's gender... will test it using CNN\n",
    "fig = plt.figure(figsize=(24, 10))\n",
    "for i, r in enumerate([random.randint(0, images.shape[0]) for _ in range(4)]):\n",
    "    ax = plt.subplot(2, 4, i + 1)\n",
    "    ax.set_title(data.iloc[r, 5])\n",
    "    ax.imshow(images[r])\n",
    "    print(r, get_cat_string('age', data.iloc[r, 0]), get_cat_string('gender', data.iloc[r, 1]), get_cat_string('size', data.iloc[r, 2]), get_cat_string('coat', data.iloc[r, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Import ml libraries\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "   print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets\n",
    "# Train - 0.6 : Val - 0.2 : Test - 0.2\n",
    "# Breeds - [:, 4] are labels, images are X\n",
    "\n",
    "label_cols = pd.DataFrame(to_categorical(data[LABELS]), columns=['c1', 'c2', 'c3'])\n",
    "label_cols.index = data.index\n",
    "#data_cat = data.copy()\n",
    "#data_cat = pd.concat([data_cat, label_cols], axis=1).drop(['coat'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, label_cols, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "print(len(y_train))\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = data.copy()\n",
    "ca = pd.DataFrame(to_categorical(test['coat']), columns=['c1', 'c2', 'c3'])\n",
    "ca.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([test, ca], axis=1).loc[:, ['c1', 'c2', 'c3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chekpoints callback function\n",
    "def make_checkpoints(name):\n",
    "    return callbacks.ModelCheckpoint(filepath=os.path.join(CHECKPOINTS_DIR, name + '.ckpt'), save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graphs functions\n",
    "def plot_accuracy(history, path):\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'Accuracy_Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(path)\n",
    "    plt.show()\n",
    "def plot_loss(history, path):\n",
    "    plt.plot(history.history['loss'], label='Loss')\n",
    "    plt.plot(history.history['val_loss'], label = 'Loss_Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network 1 - Basic CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test 1 - Deep CNN architecture (Demo)\n",
    "- The network is overfitting. Validation accuracy cannot escape from the local minima\n",
    "- Validation accuracy is between 60% and 70% after 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(RESOLUTION, RESOLUTION, 3)))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dropout(0.5))\n",
    "model_1.add(layers.Dense(512, activation='relu'))\n",
    "model_1.add(layers.Dense(len(coat_list), activation='sigmoid'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No need to train this\n",
    "epochs = 1\n",
    "#opt = optimizers.Adam(lr = 0.01)\n",
    "\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "#history_1 = model_1.fit(X_train, to_categorical(y_train), epochs=epochs, validation_data=(X_val, to_categorical(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_accuracy(history_1)\n",
    "#plot_loss(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('test_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2 - Deep CNN architecture with augumented images\n",
    "- This is a machine killer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(RESOLUTION, RESOLUTION, 3)))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Flatten())\n",
    "model_2.add(layers.Dropout(0.5))\n",
    "model_2.add(layers.Dense(512, activation='relu'))\n",
    "model_2.add(layers.Dense(len(coat_list), activation='sigmoid'))\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate extra training images from Zoom, Flip, Rotation\n",
    "dg = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "dg.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch = 4\n",
    "lr = 0.0005\n",
    "mtm = 0.9 # for RMSprop opt\n",
    "opt = optimizers.Adam(learning_rate=lr)\n",
    "#opt = optimizers.RMSprop(learning_rate=lr, momentum=mtm)\n",
    "n = 'test_'+LABELS+'_cnn_augmented'\n",
    "\n",
    "model_2.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history_2 = model_2.fit(dg.flow(X_train, y_train, batch_size=batch), \n",
    "                        steps_per_epoch = len(X_train) / batch, epochs=epochs, \n",
    "                        validation_data=(X_val, y_val), \n",
    "                        callbacks=[make_checkpoints(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = FIGURES_DIR+'basic_CNN_'+LABELS+'/'\n",
    "name = 'test_'+LABELS\n",
    "if not os.path.exists(p.rsplit('/',1)[0]):\n",
    "    os.makedirs(p.rsplit('/',1)[0])\n",
    "\n",
    "name_acc = p+name+'_epochs_'+str(epochs)+'_acc.png'\n",
    "plot_accuracy(history_2,name_acc)\n",
    "name_loss = p+name+'_epochs_'+str(epochs)+'_loss.png'\n",
    "plot_loss(history_2,name_loss)\n",
    "# Learning rate and Epochs may need changes. Currently 0.001 by default for Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../History/test_'+LABELS+'_epochs_'+str(epochs), 'wb') as file_pi:\n",
    "        pickle.dump(history_2.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "y_pred = model_2.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "#print(to_categorical(train_y).shape)\n",
    "y_true = np.argmax(to_categorical(y_test),axis = 1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(len(pd.unique(y_pred_classes)))\n",
    "\n",
    "print(confusion_mtx)\n",
    "\n",
    "br = pd.unique(y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "c = sns.heatmap(confusion_mtx, annot=True, fmt='g')\n",
    "c.set(xticklabels=br, yticklabels=br)\n",
    "plt.savefig(p+'Basic_heatmap_epochs_'+str(epochs)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print single prediction\n",
    "# print(y_pred[0])\n",
    "# plt.imshow(val_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = FIGURES_DIR+'basic_CNN_'+LABEL+'/'\n",
    "#name = 'test_'+LABEL\n",
    "#if not os.path.exists(p.rsplit('/',1)[0]):\n",
    "#    os.makedirs(p.rsplit('/',1)[0])\n",
    "\n",
    "#plt.plot(history_2.history['accuracy'], label='training data')\n",
    "#plt.plot(history_2.history['val_accuracy'], label='validation data')\n",
    "#t = 'Accuracy with '+str(epochs)+' Epochs'\n",
    "#plt.title(t)\n",
    "#plt.ylabel('Accuracy')\n",
    "#plt.xlabel('No. epoch')\n",
    "#plt.legend(loc=\"upper left\")\n",
    "#name = p+name+'_epochs_'+str(epochs)+'.png'\n",
    "#plt.savefig(name)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network 2 - Combine Net\n",
    "- Keras functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               66048     \n",
      "=================================================================\n",
      "Total params: 97,312\n",
      "Trainable params: 97,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Categorical Features - Input Layer 1\n",
    "input_cat = Input(shape=(4,))\n",
    "x_cat = layers.Dense(32)(input_cat)\n",
    "x_cat = layers.Dense(32)(input_cat)\n",
    "x_cat = layers.Dense(64)(x_cat)\n",
    "x_cat = layers.Dense(64)(x_cat)\n",
    "x_cat = layers.Dense(128)(x_cat)\n",
    "x_cat = layers.Dense(128)(x_cat)\n",
    "x_cat = layers.Dense(512)(x_cat)\n",
    "x_cat = Model(inputs=input_cat, outputs=x_cat)\n",
    "x_cat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 93,248\n",
      "Trainable params: 93,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Visual Features - Input Layer 2\n",
    "input_img = Input(shape=(RESOLUTION, RESOLUTION, 3))\n",
    "\n",
    "x_img = layers.Conv2D(32, (3, 3), activation='relu')(input_img)\n",
    "x_img = layers.MaxPooling2D((2, 2))(x_img)\n",
    "x_img = layers.Conv2D(64, (3, 3), activation='relu')(x_img)\n",
    "x_img = layers.MaxPooling2D((2, 2))(x_img)\n",
    "x_img = layers.Conv2D(128, (3, 3), activation='relu')(x_img)\n",
    "x_img = layers.MaxPooling2D((2, 2))(x_img)\n",
    "x_img = layers.Flatten()(x_img)\n",
    "x_img = layers.Dropout(0.5)(x_img)\n",
    "x_img = Model(inputs=input_img, outputs=x_img)\n",
    "\n",
    "x_img.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 126, 126, 32) 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 63, 63, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 61, 61, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           2112        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          8320        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 25088)        0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          66048       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 25088)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 25600)        0           dense_6[0][0]                    \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          13107712    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            1539        dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,299,811\n",
      "Trainable params: 13,299,811\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Combine Model\n",
    "combine_input = layers.Concatenate(axis=1)([x_cat.output, x_img.output])\n",
    "\n",
    "x_combine = layers.Dense(512, activation='sigmoid')(combine_input)\n",
    "x_combine = layers.Dense(len(coat_list), activation='softmax')(x_combine)\n",
    "\n",
    "model_3 = Model(inputs=[x_cat.input, x_img.input], outputs = x_combine)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25163, 4) (8388, 4) (8388, 4)\n",
      "(25163, 128, 128, 3) (8388, 128, 128, 3) (8388, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "\n",
    "# One-hot encoding\n",
    "label_cols = pd.DataFrame(to_categorical(data[LABELS]), columns=['c1', 'c2', 'c3'])\n",
    "label_cols.index = data.index\n",
    "\n",
    "# Split into 0.6:0.2:0.2\n",
    "X_cat_train, X_cat_test, y_train, y_test = train_test_split(\n",
    "    data.drop([LABELS], axis=1), \n",
    "    label_cols, \n",
    "    test_size=0.2, \n",
    "    random_state=1)\n",
    "X_cat_train, X_cat_val, y_train, y_val = train_test_split(\n",
    "    X_cat_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "X_img_train = load_images(X_cat_train)\n",
    "X_img_test = load_images(X_cat_test)\n",
    "X_img_val = load_images(X_cat_val)\n",
    "\n",
    "X_cat_train = X_cat_train.drop(['image'], axis=1)\n",
    "X_cat_test = X_cat_test.drop(['image'], axis=1)\n",
    "X_cat_val = X_cat_val.drop(['image'], axis=1)\n",
    "\n",
    "print(X_cat_train.shape, X_cat_test.shape, X_cat_val.shape)\n",
    "print(X_img_train.shape, X_img_test.shape, X_img_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate extra training images from Zoom, Flip, Rotation\n",
    "#dgc = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #rotation_range=30,\n",
    "    #zoom_range=0.2,\n",
    "    #horizontal_flip=True)\n",
    "#dgc.fit(X_img_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1572/1572 [==============================] - 26s 15ms/step - loss: 0.5437 - accuracy: 0.6295 - val_loss: 0.5152 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00001: saving model to ../History\\test_coat_cnn_combined.ckpt\n",
      "Epoch 2/30\n",
      "1572/1572 [==============================] - 23s 14ms/step - loss: 0.5181 - accuracy: 0.6290 - val_loss: 0.5190 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00002: saving model to ../History\\test_coat_cnn_combined.ckpt\n",
      "Epoch 3/30\n",
      "1572/1572 [==============================] - 23s 14ms/step - loss: 0.5186 - accuracy: 0.6318 - val_loss: 0.5213 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00003: saving model to ../History\\test_coat_cnn_combined.ckpt\n",
      "Epoch 4/30\n",
      "1572/1572 [==============================] - 21s 13ms/step - loss: 0.5179 - accuracy: 0.6315 - val_loss: 0.5138 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00004: saving model to ../History\\test_coat_cnn_combined.ckpt\n",
      "Epoch 5/30\n",
      "1572/1572 [==============================] - 21s 13ms/step - loss: 0.5242 - accuracy: 0.6266 - val_loss: 0.5347 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00005: saving model to ../History\\test_coat_cnn_combined.ckpt\n",
      "Epoch 6/30\n",
      "1572/1572 [==============================] - 21s 13ms/step - loss: 0.5323 - accuracy: 0.6262 - val_loss: 0.5360 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00006: saving model to ../History\\test_coat_cnn_combined.ckpt\n",
      "Epoch 7/30\n",
      "1572/1572 [==============================] - 21s 13ms/step - loss: 0.5436 - accuracy: 0.6289 - val_loss: 0.5442 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00007: saving model to ../History\\test_coat_cnn_combined.ckpt\n",
      "Epoch 8/30\n",
      "1572/1572 [==============================] - 20s 13ms/step - loss: 0.5424 - accuracy: 0.6283 - val_loss: 0.5363 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00008: saving model to ../History\\test_coat_cnn_combined.ckpt\n",
      "Epoch 9/30\n",
      "1539/1572 [============================>.] - ETA: 0s - loss: 0.5416 - accuracy: 0.6305"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-abcd1aff226e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m history_3 = model_3.fit(\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_cat_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_img_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "epochs = 30\n",
    "batch = 16\n",
    "lr = 0.0004\n",
    "mtm = 0.9 # for RMSprop opt\n",
    "opt = optimizers.Adam(learning_rate=lr)\n",
    "#opt = optimizers.RMSprop(learning_rate=lr, momentum=mtm)\n",
    "n = 'test_'+LABELS+'_cnn_combined'\n",
    "\n",
    "model_3.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history_3 = model_3.fit(\n",
    "    x = [X_cat_train, X_img_train],\n",
    "    y = y_train,\n",
    "    validation_data = ([X_cat_val, X_img_val], y_val),\n",
    "    epochs=epochs, \n",
    "    batch_size=batch,\n",
    "    steps_per_epoch = len(X_cat_train) / batch,\n",
    "    callbacks=[make_checkpoints(n)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history_3, os.path.join(FIGURES_DIR, 'basic_CNN_coat', 'test_coat_combine_15_acc.png'))\n",
    "plot_loss(history_3, os.path.join(FIGURES_DIR, 'basic_CNN_coat', 'test_coat_combine_15_loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_3.predict([X_cat_test, X_img_test])\n",
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot\n",
    "plt.imshow(X_img_test[1])\n",
    "print('Actual:\\n', y_test.iloc[1, :])\n",
    "print('Predicted:\\n', np.round(y_test_pred[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
